# 📘 32일차 TIL: 추천 시스템: 수치로 이해하는 취향의 세계

### 1. 추천의 두 가지 큰 줄기

* **콘텐츠 기반 필터링 (Content-based Filtering):** 사용자가 좋아했던 아이템과 비슷한 '특성'을 가진 다른 아이템을 추천 (예: 액션 영화를 본 사람에게 다른 액션 영화 추천).
* **협업 필터링 (Collaborative Filtering):** 나와 비슷한 취향을 가진 '다른 사용자'의 데이터를 활용해 추천.

### 2. 거리와 유사도: K-NN 알고리즘

* **K-Nearest Neighbors (K-최근접 이웃):** 데이터 중심에서 가장 가까운 $k$개의 데이터를 찾아 그들의 특성을 반영하는 알고리즘입니다.
* 추천 시스템에서는 "나와 가장 유사한 거리(또는 유사도)에 있는 상위 $k$명의 이웃이 산 물건"을 추천할 때 사용합니다.

---

### 3. 수학적 핵심: 내적(Dot Product)과 유사도

이 부분에서 혼동하기 쉬운 개념을 바로잡아 드릴게요.

* **내적과 행렬곱:** 두 벡터의 내적값은 두 데이터가 **얼마나 같은 방향을 향하고 있는가**를 나타냅니다.
* **공분산과 상관계수:** * 내적값 자체는 데이터의 크기에 영향을 받습니다.
* 이를 각 데이터의 크기(표준편차)로 나누어 정규화하면 **코사인 유사도(Cosine Similarity)**가 되는데, 이는 통계학의 **상관계수($r$)**와 수학적으로 매우 유사한 의미를 갖습니다.
* **양적 선형 관계:** 내적값이 크고 코사인 값이 1에 가까움 (취향 일치).
* **음적 선형 관계:** 코사인 값이 -1에 가까움 (취향 정반대).



---

### 4. 잠재 요인(Latent Factor) 협업 필터링

사용자와 아이템 사이의 보이지 않는 '특징'을 찾아내는 방식입니다.

* **행렬 분해 (Matrix Factorization):** 거대한 `(User × Item)` 행렬을 두 개의 작은 행렬인 `(User × Factor)`와 `(Factor × Item)`으로 쪼개는 기법입니다.
* **Factor(잠재 요인)의 의미:** 예를 들어 영화라면 '감독의 스타일', '긴장감', '로맨스 지수' 같은 추상적인 특징이 될 수 있습니다.
* **행렬곱의 결과:** 두 행렬을 다시 곱하면(내적하면) 원래 비어있던 칸(평점을 매기지 않은 칸)의 예상 점수가 채워집니다. 이 점수가 높은 아이템을 추천하는 것이죠.

---

### 5. "내적을 유지한 상태로 변환한다"는 의미 (질문 9번 답변)

이 말은 **데이터의 본질적 구조(관계)를 해치지 않는다**는 뜻입니다.

* 데이터를 분석하기 편하게 차원을 축소하거나 변환(Transformation)하더라도, **데이터들 사이의 상대적인 거리나 각도(내적값)가 유지**되어야 합니다.
* 내적이 유지된다는 것은 변환 후에도 "A와 B는 비슷하고, C와는 멀다"라는 **데이터 간의 관계성(본질)**이 보존된다는 뜻입니다. 이것이 보존되어야만 변환된 공간에서도 정확한 추천이 가능합니다.

---

### 6. 딥러닝과 행렬 연산 (질문 10번)

* 정확한 통찰입니다! 딥러닝 모델의 내부 계산은 수억 번의 **행렬 곱셈($Wx + b$)**으로 이루어져 있습니다.
* 따라서 GPU(그래픽 처리 장치)가 딥러닝에 유리한 이유도 수많은 단순 행렬 연산을 동시에(병렬로) 처리하는 데 특화되어 있기 때문입니다.
