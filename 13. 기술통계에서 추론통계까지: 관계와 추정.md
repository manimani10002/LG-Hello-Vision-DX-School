# 📘 13일차 TIL: 기술통계에서 추론통계까지: 관계와 추정
## 1. 다변량 데이터 탐색: 관계의 시작
### 1) 상관관계 vs 인과관계
- 상관관계(Correlation): "A가 변할 때 B도 변하는가?" (방향과 강도). 두 변수가 같이 움직이지만, 무엇이 원인인지는 알 수 없음.
    - 예: 아이스크림 판매량과 익사 사고 수 (둘 다 '기온'이라는 제3의 변수 영향)
- 인과관계(Causation): "A가 원인이 되어 B가 변하는가?" (원인과 결과).
    - 회귀분석(Regression): 독립변수($X$)가 종속변수($Y$)에 미치는 영향력을 수식($Y = wX + b$)으로 모델링하여 인과관계의 크기를 예측함.
### 2) 공분산($Cov$) vs 상관계수($Cor$)
- 공분산: 두 변수의 변화 방향과 크기를 나타냄. 하지만 데이터의 **단위(Unit)**에 민감함. (예: 원화로 계산할 때와 달러로 계산할 때 값이 확 달라짐)
- 상관계수: 공분산을 각 변수의 표준편차로 나누어 **단위를 제거(Standardization)**한 값.
    - 범위: $-1 \le r \le 1$.
    - 분석가의 판단 흐름: cor()로 관계의 강도를 먼저 파악 → 유의미하다면 cov()나 회귀분석으로 구체적인 변화량 계산.
## 2. 상관관계 분석 기법 (Python 실습 코드 포함)
### 1) 분석 기법 결정 
#### 1. 트리데이터가 정규성을 따르는가? (Shapiro-Wilk Test)
- Yes: 피어슨(Pearson) - 선형적 관계 측정.
- No: 스피어만(Spearman) - 순위 기반, 비선형적/단조적 관계.
#### 2. 데이터가 아주 적거나 동점이 많은가?
- Yes: 켄달(Kendall) - 순위 쌍의 일치성 측정.
### 2) Python 시각화 예제 코드
```Python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import shapiro

# 1. 데이터 준비 (예시)
data = sns.load_dataset('mpg').dropna() # 자동차 연비 데이터

# 2. 정규성 검정 (EDA의 필수 과정)
stat, p = shapiro(data['mpg'])
print(f'Shapiro-Wilk p-value: {p:.4f}') # 0.05보다 작으면 비모수(Spearman) 권장

# 3. 산점도 (Scatter Plot)
plt.figure(figsize=(8, 5))
sns.scatterplot(data=data, x='horsepower', y='mpg')
plt.title('Horsepower vs MPG Scatter Plot')
plt.show()

# 4. 상관계수 히트맵 (Heatmap)
plt.figure(figsize=(10, 8))
corr_matrix = data.corr(method='pearson') # 혹은 'spearman'
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Heatmap')
plt.show()
```

## 3. 추론통계학의 핵심: 중심극한정리
### 1) 용어의 정확한 교정
- 통계량(Statistic): 표본에서 얻은 값 ($\bar{X}, s$)
- 모수(Parameter): 모집단이 가진 진짜 값 ($\mu, \sigma$)
- 오류 수정: "표본 표준편차"를 신뢰구간 공식에 쓸 때는 **표준오차(Standard Error)**라는 명칭을 사용해야 함.
### 2) 중심극한정리(CLT)의 3대 공식
모집단($\mu, \sigma$)에서 크기가 $n$인 표본을 무한히 뽑을 때, 표본평균($\bar{X}$)의 분포는:
#### 1. 평균: $E(\bar{X}) = \mu$ (표본평균들의 평균은 모평균과 같다)
#### 2. 분산: $Var(\bar{X}) = \frac{\sigma^2}{n}$ (표본이 커질수록 평균들의 변동성은 줄어든다)
#### 3. 모양: $n \ge 30$이면 모집단의 분포와 상관없이 **정규분포 $N(\mu, \frac{\sigma^2}{n})$**를 따른다.

## 4. 구간추정과 가설검정
### 1) 신뢰구간 (Confidence Interval)
- 공식: $\bar{X} \pm (Z_{\alpha/2} \times \frac{s}{\sqrt{n}})$
- 해석: "95% 신뢰구간이 $[10, 20]$이다"라는 말은, "이런 방식으로 구간을 100번 구하면 그중 95번은 진짜 모평균 $\mu$를 포함한다"는 뜻임. (단일 구간 안에 $\mu$가 있을 확률이 95%라는 점추정적 해석과는 미묘하게 다름)
### 2) 가설검정의 논리 구조
#### 1. 귀무가설($H_0$): 차이가 없다. (차이가 있다면 그건 우연이다.)
#### 2. 대립가설($H_1$): 차이가 있다. (우연이라고 하기엔 너무 특이하다.)
#### 3. p-value: 귀무가설이 맞다는 전제하에, 현재 데이터 이상의 결과가 나올 확률.
- p < 0.05: "우연일 확률이 5% 미만이다." → 귀무가설 기각(유의미함)

## 5. 보완할 내용: R cor.test() 결과 해석법
실습 코드에 적어주신 cor.test(a, b) 결과는 다음과 같이 해석합니다:
- t: 검정 통계량 (절대값이 클수록 상관관계가 뚜렷함)
- p-value: 0.05보다 작으면 "상관계수가 0이 아니라고 말할 통계적 근거가 충분하다"는 뜻.
- sample estimates (cor): 실제 상관계수 값 ($r$).
- 95 percent confidence interval: 상관계수 자체의 신뢰구간. 이 구간 안에 0이 포함되지 않아야 통계적으로 유의미한 상관관계임.
