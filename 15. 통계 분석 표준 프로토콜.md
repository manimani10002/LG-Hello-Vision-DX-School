# 📘 15일차 TIL: [통계 분석 표준 프로토콜]

어떤 분석을 하든 이 과정은 반드시 거쳐야 합니다.

```r
# 1. 환경 설정 및 데이터 로드
setwd("C:\\Users\\user\\Desktop\\Rwork") # 작업 경로 설정
df <- read.csv("your_data.csv", header=TRUE)

# 2. 데이터 탐색 (생김새 확인)
str(df)       # 데이터 구조 확인
summary(df)   # 결측치(NA) 유무 및 기초 통계 확인

# 3. 데이터 전처리 (Subset 및 결측치 제거)
# 분석할 컬럼에 NA가 있으면 분석이 중단되므로 미리 제거합니다.
# 분석에 필요한 컬럼들만 쏙 뽑아 clean_df를 만듭니다.
clean_df <- subset(df, !is.na(score_a) & !is.na(score_b)) 

```

---

### 📊 [분석별 선택 코드] 분석 목적에 따라 골라 쓰기

#### 1. 일표본 T-검정 (One-sample T-test)

* **목적:** "우리 집단 평균이 특정 기준값()과 다른가?"
* **예시:** 우리 반 평균 점수가 80점인지 확인

```r
# 단계 1: 정규성 검사 (shapiro.test)
shapiro.test(clean_df$score_a)

# 단계 2: 분석 수행
# 정규성 만족(p > 0.05) 시 t.test / 불만족 시 wilcox.test
t.test(clean_df$score_a, mu = 80)          # 기준값(mu) 입력
wilcox.test(clean_df$score_a, mu = 80)     # 정규성 탈락 시 대안

```

#### 2. 독립표본 T-검정 (Independent T-test)

* **목적:** "서로 다른 A집단과 B집단의 평균이 다른가?"
* **예시:** 남학생과 여학생의 성적 비교

```r
# 단계 1: 집단 변수를 Factor로 변환 (R에게 집단임을 알림)
clean_df$group <- as.factor(clean_df$group)

# 단계 2: 정규성 검사 (각 집단별로 실시)
shapiro.test(clean_df$score[clean_df$group == "A"])
shapiro.test(clean_df$score[clean_df$group == "B"])

# 단계 3: [정규성 만족 시] 등분산 검사 (var.test)
vt <- var.test(score ~ group, data = clean_df)

# 단계 4: 최종 분석 수행
# var.equal 옵션에 등분산 검사 결과(p > 0.05 여부)를 자동으로 넣음
t.test(score ~ group, data = clean_df, var.equal = (vt$p.value > 0.05))
wilcox.test(score ~ group, data = clean_df) # 정규성 탈락 시 대안

```

#### 3. 대응표본 T-검정 (Paired T-test)

* **목적:** "동일한 대상의 전(Before)과 후(After)가 다른가?"
* **예시:** 다이어트 약 복용 전후의 몸무게 변화

```r
# 단계 1: 정규성 검사 (전-후의 '차이값'이 정규성을 따르는지 확인)
diff <- clean_df$after - clean_df$before
shapiro.test(diff)

# 단계 2: 분석 수행
# paired = TRUE 옵션이 핵심!
t.test(clean_df$before, clean_df$after, paired = TRUE)
wilcox.test(clean_df$before, clean_df$after, paired = TRUE) # 정규성 탈락 시 대안

```

#### 4. 상관분석 (Correlation Analysis)

* **목적:** "두 숫자 데이터가 서로 관련이 있는가?"
* **예시:** 공부 시간과 시험 점수의 관계
```r
# 단계 1: 시각화 (산점도)
plot(clean_df$var1, clean_df$var2)

# 단계 2: 상관계수 및 유의성 검정
# method는 기본이 pearson(모수), 정규성 탈락 시 "spearman" 사용
cor.test(clean_df$var1, clean_df$var2, method = "pearson")

```

#### 5. 카이제곱 검정

* **목적:** 두 범주형 변수 사이에 "연관성이 있는가?" 혹은 "분포의 차이가 있는가?"를 확인합니다.
* **예시:** 요금제 종류(A/B/C)에 따라 고객의 이탈 여부(유지/해지) 비중이 다른가?
```r
# 워킹디렉토리 이동
getwd()
setwd("C:/Users/user/Desktop/Rwork/")

# gmodel install 후 import해오기
install.packages("gmodels")
library(gmodels) # CrossTable() 함수 사용

# 데이터셋 파일 읽어와서 오기
df <- read.csv("cleanDescriptive.csv", header = TRUE, fileEncoding = "EUC-KR")

# 데이터셋 구조 보기
str(df)
summary(df)

# 내가 확인할 칼럼 선택하고, Nan값 제거해서 clean_df에 할당하기
clean_df <- subset(df, !is.na(level) & !is.na(pass), select = c(level, pass))

# import 해온 gmodels의 CrossTable() 사용하기
CrossTable(x = clean_df$level, 
           y = clean_df$pass, 
           chisq = TRUE)


# 예를들어 결과 값이 아래와 같을때
# ----------------------------------------------
# Pearson's Chi-squared test 

# Chi^2 =  2.766951     d.f. =  2     p =  0.2507057 
# ----------------------------------------------
# 해석: 
# X-squared = 2.767: 기대치와 관측치의 '어긋남'의 합이 2.767입니다. (그리 크지 않은 수치입니다.)
# df = 2: 자유도가 2인 카이제곱 지도를 사용했습니다.
# p-value = 0.2507: 이 어긋남이 우연히 발생할 확률이 약 25%나 됩니다.
# 따라서, "p-value가 0.2507로 유의수준 0.05보다 크므로, 학력(level)과 합격여부(pass) 사이에는 유의미한 연관성이 없다(독립적이다)."
```
#### 6. 일원 분산분석 (One-way ANOVA)

* **목적:** "세 개 이상의 집단(A, B, C...) 간에 평균 차이가 존재하는가?"
* **예시:** 학력(고졸/대졸/대학원졸)에 따른 연봉 차이 비교
* **핵심 지표: F-값** (집단 내 분산 대비 집단 간 분산의 비율)
```r
# 단계 1: 집단 변수를 Factor로 변환 (필수)
clean_df$group <- as.factor(clean_df$group)

# 단계 2: 정규성 검사 (각 집단별로 모두 정규성을 만족해야 함)
# tapply를 쓰면 그룹별로 한 번에 shapiro 검사를 할 수 있어 편리합니다.
tapply(clean_df$score, clean_df$group, shapiro.test)

# 단계 3: 등분산 검사 (Bartlett 검정)
# ANOVA는 모든 집단의 분산이 같다는 가정이 중요합니다.
bartlett.test(score ~ group, data = clean_df)

# 단계 4: 본 분석 수행 (F-검정)
# p < 0.05이면 "적어도 한 집단은 평균이 다르다"는 뜻입니다.
result <- aov(score ~ group, data = clean_df)
summary(result)

# 단계 5: 사후 검정 (Post-hoc) - "누가 범인인가?"
# ANOVA 결과가 유의미(p < 0.05)할 때만 수행합니다.
# 어떤 집단끼리 구체적으로 차이가 나는지 1:1로 매칭해줍니다.
TukeyHSD(result) 
plot(TukeyHSD(result)) # 시각적으로 차이 확인
```
💡 F-검정 결과 해석 가이드 (TIL 보충용)
* F-value (F-값): - 집단 간의 거리(신호)를 집단 내의 개인차(소음)로 나눈 값입니다.

  - 이 값이 1보다 훨씬 크다면 "개인차를 무시할 만큼 집단 간 차이가 뚜렷하다"는 신호입니다.

* Pr(>F) (p-value):

  - "모든 집단의 평균이 같다"는 세상에서 이런 F-값이 나올 확률입니다.

  - 0.05보다 작다면? "우연이 아니다! 집단 간에 유의미한 평균 차이가 있다"고 결론 내립니다.

* 사후 검정(TukeyHSD)이 필요한 이유:

  - F-검정(ANOVA)은 "누군가 한 명은 범인(차이 있음)이다"라고만 알려줍니다.

  - 정확히 A와 B가 다른지, B와 C가 다른지 지목하기 위해 사후 검정을 실시합니다.

### p-value가 말해주는 진짜 의미

* p-value는 **"내가 선택한 분포 지도에서, 현재 내 데이터보다 더 극단적인 결과가 나올 확률"** 입니다.
* p-value가 0.05보다 작다면? ($p < 0.05$)
  - "이렇게 희귀한 일이 우연히 일어날 리가 없어. 두 집단 사이에는 진짜 차이가 있구나!" (귀무가설 기각)
* p-value가 0.05보다 크다면? ($p \ge 0.05$)
  - "이 정도 차이는 그냥 우연히 일어날 수 있는 수준이야. 차이가 있다고 말할 수 없어." (귀무가설 채택)
* 즉 p-value가 커서 귀무가설을 기각하지 않는다면 현제세계(현재분포)를 따른다고 말할수있다.
* **가정 검정(shapiro 등)** 에서는 현재 세계를 따라야 (p > 0.05) 다음 분석으로 갈 수 있고, **본 분석(t.test 등)** 에서는 현재 세계를 탈출해야 (p < 0.05) 우리가 원하는 "의미 있는 발견"을 한 것이 됩니다.
