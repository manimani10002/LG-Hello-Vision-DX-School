## 💡 [39일차] 이미지 딥러닝과 다층 퍼셉트론(MLP)

### 1. 이미지 데이터와 Tensor Shape

이미지는 컴퓨터에게 단순한 숫자 행렬입니다.

* **`train_images.shape` -> `(60000, 28, 28)`의 의미:**
* **60,000:** 전체 이미지의 개수 (데이터셋의 크기)입니다.
* **28:** 이미지의 세로 픽셀 수입니다.
* **28:** 이미지의 가로 픽셀 수입니다.
* *참고:* 만약 컬러 이미지라면 채널(RGB) 정보가 추가되어 `(60000, 28, 28, 3)`의 형태가 됩니다.


* **메타데이터 활용:** 이미지 딥러닝 시 단순히 픽셀값(색상)뿐만 아니라 촬영 시간, 위치, 조리개 값 등의 메타데이터를 함께 학습시키면 모델의 예측력을 더욱 높일 수 있습니다.

---

### 2. 인공신경망의 계층 구조

#### ① 단층 퍼셉트론 (Single-Layer Perceptron)

* **구조:** 입력층과 **출력층**으로만 구성됩니다. (입력층은 연산이 일어나지 않으므로 층 수에서 제외합니다.)
* **한계:** 선형 분리만 가능하여, 간단한 논리 회로(AND, OR)는 풀 수 있지만 **XOR 문제** 같은 복잡한 비선형 문제는 해결하지 못합니다.

#### ② 다층 퍼셉트론 (Multi-Layer Perceptron, MLP)

* **핵심 원리:** 입력층과 출력층 사이에 **은닉층(Hidden Layer)**이 추가된 형태입니다.
* **데이터 융합:** 님께서 언급하신 것처럼, 입력값()이 여러 노드를 거치며 각각 다른 가중치()와 곱해집니다. 이 과정에서 데이터의 '다양한 관점'이 추출되고, 활성화 함수를 통해 융합되어 다음 층으로 전달()됩니다. 층이 깊어질수록 더 추상적이고 본질적인 특징을 학습하게 됩니다.

---

### 3. 딥러닝 모델의 종류와 생성 과정

#### 💡 주요 모델 종류

1. **ANN (Artificial Neural Network):** 가장 기본적인 다층 퍼셉트론 구조. 정형 데이터 분석에 유리.
2. **CNN (Convolutional Neural Network):** 이미지의 공간 정보를 유지하며 학습. **이미지 처리에 특화.**
3. **RNN (Recurrent Neural Network):** 과거의 정보가 현재에 영향을 주는 구조. 시계열 데이터나 자연어 처리에 특화.

#### 🛠 모델 생성 5단계

1. **데이터 전처리:** 텐서 변환, 정규화(Scaling), 데이터 분할.
2. **모델 정의:** `Sequential` 등을 사용해 층(Layer)을 쌓음.
3. **컴파일(Compile):** 손실 함수(Loss), 최적화 도구(Optimizer), 평가 지표(Metrics) 설정.
4. **학습(Fit):** 데이터를 모델에 넣고 가중치를 업데이트.
5. **평가 및 예측:** 테스트 데이터를 통해 성능 확인.

---

### 4. 텐서플로우 실습 코드 (MNIST 숫자 분류)

```python
import tensorflow as tf
from tensorflow.keras import layers, models

# 1. 데이터 로드 및 전처리
mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# 픽셀값(0~255)을 0~1 사이로 정규화 (학습 효율 상승)
x_train, x_test = x_train / 255.0, x_test / 255.0

# 2. 모델 정의 (다층 퍼셉트론)
model = models.Sequential([
    # 28x28의 2D 이미지를 1D(784줄)로 쭉 펴주는 층
    layers.Flatten(input_shape=(28, 28)), 
    
    # 은닉층: 128개의 노드, ReLU 활성화 함수로 비선형성 추가
    layers.Dense(128, activation='relu'), 
    
    # 출력층: 10개 숫자(0~9)로 분류, Softmax로 확률값 출력
    layers.Dense(10, activation='softmax') 
])

# 3. 모델 컴파일
model.compile(optimizer='adam',                # 가중치를 업데이트하는 최적화 알고리즘
              loss='sparse_categorical_crossentropy', # 다중 분류를 위한 손실 함수
              metrics=['accuracy'])            # 평가는 정확도로 진행

# 4. 모델 학습
# epochs=5: 전체 데이터를 5번 반복해서 학습함
model.fit(x_train, y_train, epochs=5)

# 5. 모델 평가
test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)
print(f'\n테스트 정확도: {test_acc}')

```

---

### 5. 평가 방법 (Evaluation)

* **Loss (손실):** 모델의 예측값과 실제값의 차이입니다. 낮을수록 좋습니다.
* **Accuracy (정확도):** 전체 중 맞게 예측한 비율입니다. 분류 모델의 대표 지표입니다.
* **Overfitting 확인:** 학습 데이터의 성능은 높지만 테스트 데이터의 성능이 낮다면, 모델이 공부한 것만 달달 외운 '과적합' 상태임을 의미합니다.

---

**오늘의 학습 요약:**
이미지 데이터의 형상을 이해하고, **다층 퍼셉트론**을 통해 여러 관점의 가중치를 융합하여 정답을 찾아가는 과정을 배우셨습니다. 특히 **Flatten** 층을 통해 2D 이미지를 1D로 펴주는 과정이 MLP 이미지 분석의 핵심입니다.
