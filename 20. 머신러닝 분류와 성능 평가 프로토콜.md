# 📘 20일차 TIL: 머신러닝 분류와 성능 평가 프로토콜

## 1. 머신러닝 프레임워크 및 분류

* **프레임워크:** `scikit-learn`(전통적 ML), `TensorFlow/Keras`(딥러닝).
* **지도학습 (Supervised):** 정답($y$)이 있는 데이터 학습. (분류, 회귀)
* **비지도학습 (Unsupervised):** 정답 없이 패턴 찾기. (군집화, 차원 축소)

---

## 2. 오차행렬 (Confusion Matrix)

모델이 예측한 결과와 실제 정답을 교차 표로 나타낸 것입니다.

```python
from sklearn.metrics import confusion_matrix

# 실제값(y_true)과 모델의 예측값(y_pred)
y_true = [0, 1, 0, 1, 1, 0, 1, 1]
y_pred = [0, 1, 1, 0, 1, 0, 1, 1]

cm = confusion_matrix(y_true, y_pred)
print(cm)
# 결과 예시:
# [[2 1]  <- [TN, FP]
#  [1 4]] <- [FN, TP]

```

> **정확한 용어 체크:** > * **TN**: 0을 0이라 맞춤 / **TP**: 1을 1이라 맞춤
> * **FP (1종 오류)**: 0인데 1이라고 함 (스팸이 아닌데 스팸함으로 보냄)
> * **FN (2종 오류)**: 1인데 0이라고 함 (암 환자인데 정상이라고 함)
> 
> 

---

## 3. 평가 지표 및 코드 예시

정확도만으로는 '평균의 함정'에 빠질 수 있어 정밀도와 재현율을 반드시 같이 봐야 합니다.

```python
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# 1. 정확도 (Accuracy): 전체 중 맞춘 비율
acc = accuracy_score(y_true, y_pred) 

# 2. 정밀도 (Precision): 모델이 1이라고 한 것 중 진짜 1인 비율 (예측치 기준)
# 암기팁: "예"측치 기준 -> "예"정(밀도)
pre = precision_score(y_true, y_pred)

# 3. 재현율 (Recall): 실제 1인 것들 중 모델이 맞춘 비율 (실측치 기준)
# 암기팁: "실"측치 기준 -> "실"현(율)
rec = recall_score(y_true, y_pred)

# 4. F1-Score: 정밀도와 재현율의 조화 평균 (둘의 밸런스 점수)
f1 = f1_score(y_true, y_pred)

```

---

## 4. 정밀도와 재현율의 트레이드오프 (Trade-off)

두 지표는 시소와 같아서 하나를 올리면 하나가 떨어집니다. 우리는 **"어떤 오류가 더 치명적인가"**에 따라 임계값(Threshold)을 조정하여 하나를 선택해야 합니다.

* **재현율(Recall) 선택 시점 (FN을 줄여야 할 때):**
* **암 진단**: 암인데(1) 정상(0)이라고 판정하면 생명이 위험함.
* **금융 사기 검출**: 사기인데 정상 거래라고 하면 큰 손실이 발생함.


* **정밀도(Precision) 선택 시점 (FP를 줄여야 할 때):**
* **스팸 메일**: 스팸이 아닌데(0) 스팸(1)으로 처리하면 중요한 업무 메일을 놓침.
* **유죄 판결**: 무죄인 사람을 유죄로 판결하면 인권 침해가 매우 큼.



---

## 5. 최종 리포트 출력하기 (실무 팁)

하나하나 계산할 필요 없이 `classification_report`를 쓰면 한눈에 볼 수 있습니다.

```python
from sklearn.metrics import classification_report

print(classification_report(y_true, y_pred))

```
